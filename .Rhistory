percentiles_trump <- quantile(trump_df$comments, probs = c(0.25, 0.50, 0.75, 0.90, 0.95, 0.99))
print(percentiles_trump)
#Filtering the titles that contain Biden
biden_df <- politik_df %>% filter(grepl("Biden", title))
biden_df$candidate <- "Biden"
#Let's check the distribution of number of comments
percentiles_biden <- quantile(biden_df$comments, probs = c(0.25, 0.50, 0.75, 0.90, 0.95, 0.99))
print(percentiles_biden)
})
suppressWarnings({
suppressPackageStartupMessages(library(tidytext))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(quanteda))
suppressPackageStartupMessages(library(quanteda.textplots))
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(RCurl))
suppressPackageStartupMessages(library(data.table))
})
getwd()
# Read large CSV file using fread
politik1 <- fread("politics_comments1.csv")
suppressWarnings({
suppressPackageStartupMessages(library(tidytext))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(quanteda))
suppressPackageStartupMessages(library(quanteda.textplots))
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(RCurl))
suppressPackageStartupMessages(library(data.table))
})
getwd()
# Read large CSV file using fread
politik1 <- fread("politics_comments1.csv")
politik2 <- fread("politics_comments2.csv")
politik3 <- fread("politics_comments3.csv")
#Checking the structure of the data sets
glimpse(politik1)
glimpse(politik2)
glimpse(politik3)
# Cleaning and wrangling
politik_df <- politik2 %>% select(-V1, -timestamp) #eliminating non-relevant columns
politik_df <- as_tibble(politik_df)
politik_df$date <- as.Date(politik_df$date, format = "%m/%d/%Y")
politik_df2 <- politik3 %>% select(-V1, -timestamp) #eliminating non-relevant columns
politik_df2 <- as_tibble(politik_df2)
politik_df2$date <- as.Date(politik_df2$date, format = "%m/%d/%Y")
politik_df2 <- politik_df2[-(which(politik_df2$author %in% "AutoModerator")),]
politik_df3 <- politik_df2[-(which(politik_df2$author %in% "[deleted]")),]
#first I created a count column
politik_df3 <- politik_df3 %>% mutate(countid = "1")
politik_df3$countid <- as.numeric(politik_df3$countid)
#How many authors (nodes) we have here?
length(unique(politik_df3$author))
#first let's see the distribution of number of comments
percentiles <- quantile(politik_df$comments, probs = c(0.25, 0.50, 0.75, 0.90, 0.95, 0.99))
print(percentiles)
subset_politik2 <- subset(politik_df, comments >= 1439 )
glimpse(subset_politik2)
length(unique(subset_politik2$author))
subset_politik3 <- politik_df3 %>%
filter(url %in% subset_politik2$url)
#let's see the df now
glimpse(subset_politik3)
#how many nodes (authors)?
length(unique(subset_politik3$author))
suppressWarnings({
#First selecting posts with "Trump" or "Biden" included in the title of the post
#Filtering the titles that contain Trump
trump_df <- politik_df %>% filter(grepl("Trump", title))
trump_df$candidate <- "Trump"
#Let's check the distribution of number of comments
percentiles_trump <- quantile(trump_df$comments, probs = c(0.25, 0.50, 0.75, 0.90, 0.95, 0.99))
print(percentiles_trump)
})
#Trump
trump_post <- subset(trump_df, comments == 74 )
suppressWarnings({
#Filtering the titles that contain Biden
biden_df <- politik_df %>% filter(grepl("Biden", title))
biden_df$candidate <- "Biden"
#Let's check the distribution of number of comments
percentiles_biden <- quantile(biden_df$comments, probs = c(0.25, 0.50, 0.75, 0.90, 0.95, 0.99))
print(percentiles_biden)
})
#Biden
biden_post <- subset(biden_df, comments == 67 )
#merging the previous df's
trump_biden_df <- rbind(trump_post, biden_post)
print(trump_biden_df$url)
#let's identify these posts in the politik3 df (containing all the details)
subset_politik3 <- politik_df3 %>%
filter(url %in% trump_biden_df$url)
#creating a new column with the candidate related to the post
subset_politik3 <- subset_politik3 %>%
mutate(candidate = case_when(
url == "https://www.reddit.com/r/politics/comments/1bsdho2/us_election_workers_face_thousands_of_threats_so/" ~ "Trump",
url == "https://www.reddit.com/r/politics/comments/1bsnq6l/are_black_and_brown_voters_really_fleeing_biden/" ~ "Biden",
))
#let's see the df now
glimpse(subset_politik3)
# Let's keep only the relevant columns
politik_final <- select(subset_politik3, c("url", "author", "score", "comment", "comment_id", "candidate"))
# Extracting the levels of each comment and its hierarchy
politik_final2 <- politik_final %>%
mutate(Level = str_count(comment_id, pattern = "_") + 1,  # Count underscores to determine depth
ParentID = ifelse(Level > 1, sapply(strsplit(comment_id, "_"), function(x) paste(x[-length(x)], collapse = "_")), NA))
length(unique(politik_final2$author))
length(unique(politik_final2$url))
#let's create some tables to see frequencies and totals
#first I created a count column
politik_final2 <- politik_final2 %>% mutate(countid = "1")
politik_final2$countid <- as.numeric(politik_final2$countid)
#preparing tables
library(data.table)
politik_table2 <- data.table(politik_final2)
#total posts grouped by author
count_table2 <- politik_table2 %>% group_by(author) %>% summarise(Total_posts = sum(countid))
count_table2 <- count_table2 %>% arrange(desc(Total_posts))
print(count_table2)
summary_votes <- politik_table2 %>% group_by(author) %>% summarize(Total_Score = sum(score))
summary_votes <- summary_votes %>% arrange(desc(Total_Score))
print(summary_votes)
#Score as a proportion of comments
summary_score_ratio <- politik_table2 %>% group_by(author) %>% summarize(Ratio_score_per_comment = sum(score)/sum(countid))
summary_score_ratio <- summary_score_ratio %>% arrange(desc(Ratio_score_per_comment))
print(summary_score_ratio)
#Rename level column as it represent more how deep/far is the comment
#from the initial post, we will use this later as an attribute
politik_final2 <- politik_final2 %>%
rename(distance = Level)
#identify who is commenting on the same post
politik_final2 <- politik_final2 %>%
mutate(level = substr(comment_id, 1, 2))
politik_final2$level <- str_replace_all(politik_final2$level, "_", "")
politik_final2 <- politik_final2 %>%
mutate(level2 = substr(candidate, 1, 1))
politik_final2$comment_id2 <- paste(politik_final2$level2, politik_final2$level, sep = "_")
#Now I'll create a new object by keeping only the columns I need
politik_final3 <- select(politik_final2, c(-"comment_id", -"ParentID", -"level", -"level2"))
#Will create a attribute only object to use later
politik_attributes <- select(politik_final3, c("score", "candidate", "distance"))
politik_m <- select(politik_final3, c("comment_id2", "author"))
# Identify unique names and codes
unique_names <- unique(politik_final3$author)
unique_codes <- unique(politik_final3$comment_id2)
# Create an empty adjacency matrix
adj_matrix <- matrix(0, nrow = length(unique_names), ncol = length(unique_names),
dimnames = list(unique_names, unique_names))
#Populate the adjacency matrix based on shared codes
for (i in 1:length(unique_names)) {
for (j in 1:length(unique_names)) {
# Check if names i and j have the same code
shared_code <- intersect(politik_final3$comment_id2[politik_final3$author == unique_names[i]],
politik_final3$comment_id2[politik_final3$author == unique_names[j]])
if (length(shared_code) > 0) {
adj_matrix[unique_names[i], unique_names[j]] <- 1  # Set relationship to 1
}
}
}
# I'll eliminate loops in advance
diag(adj_matrix) <- 0
#load packages
library(network)
library(sna)
library(statnet)
politik.n <- network(adj_matrix, directed = FALSE)
politik.n
#Dyads and Triads census
sna::dyad.census(politik.n)
sum(sna::triad.census(politik.n))
sna::triad.census(politik.n)
#transitivity
gtrans(politik.n, mode="graph")
# get network density: statnet
network::network.density(politik.n) #already exclude loops
# Plot the network
plot(politik.n, displaylabels = TRUE, label.cex=0.7, vertex.cex=1.5, displayisolates=T, main = "Authors Network")
# Plot the network
plot(politik.n, displaylabels = TRUE, label.cex=0.7, vertex.cex=1.5, displayisolates=F, main = "Authors Network")
#I'll create a column with Biden true-false attribute
politik_final3at <- politik_final3 %>%
mutate(
biden = if_else(candidate == "Biden", "TRUE", "FALSE")
)
#now let's see how authonrs in Biden and Trump are interacting
nodeColors<-ifelse(politik_final3at$biden,"dodgerblue","red")
plot(politik.n,displaylabels=F,vertex.col=nodeColors,vertex.cex=1.2, displayisolates=T, main = "Authors Network by Candidate") #including isolated nodes
legend("bottomright", legend = c("Biden", "Trump"), col = c("dodgerblue", "red"), pch = c(21, 21), title = "Node Type")
plot(politik.n,displaylabels=F,vertex.col=nodeColors,vertex.cex=1.2, displayisolates=F, main = "Authors Network by Candidate (excluding isolated nodes)") #excluding isolated nodes
legend("bottomright", legend = c("Biden", "Trump"), col = c("dodgerblue", "red"), pch = c(21, 21), title = "Node Type")
# create a dataset of vertex names and degree: statnet
politik.nodes.df <- data.frame(name = politik.n %v% "vertex.names",
degree = sna::degree(politik.n))
politik_table7 <- data.table(politik.nodes.df)
#order by centrality degree
politik_table7 %>% arrange(desc(degree)) %>%
slice(1:10)
summary(politik_table7)
library(igraph)
# Create the igraph object
politik.ig <- graph_from_adjacency_matrix(adj_matrix, mode = "undirected")  # Undirected by default
# Calculate degree centrality for each node
degree_centrality <- degree(politik.ig, mode = "all")
# If nodes do not have names, you can use node IDs
if (is.null(V(politik.ig)$name)) {
V(politik.ig)$name <- as.character(1:vcount(politik.ig))
}
# Check node names
node_names <- V(politik.ig)$name
# Create a sample data frame with some values for each node
# Ensure the data frame has the same node identifiers as the graph
df <- data.frame(
author = node_names,  # Node names or IDs
value = runif(vcount(politik.ig), 1, 100)  # Random values between 1 and 100
)
# Convert degree centrality to a data frame
degree_centrality_df <- data.frame(
author = node_names,  # Node names or IDs
degree_centrality = degree_centrality  # Degree centrality values
)
# Merge the degree centrality data frame with the existing data frame
merged_df <- merge(df, degree_centrality_df, by = "author", all = TRUE)
merged_df2 <- merge(merged_df, politik_final2, by = "author", all = TRUE)
degree_scoredf <- select(merged_df2, c("degree_centrality", "score"))
# Calculate the correlation coefficient between 'score' and 'degree_centrality'
cor_matrix1 <- cor(degree_scoredf, use = "complete.obs")
cor_matrix1
degree_scoredf3 <- select(merged_df2, c("degree_centrality", "author"))
subset_df <- distinct(degree_scoredf3, author, .keep_all = TRUE)
subset_df %>% arrange(desc(degree_centrality))
# run clustering algorithm: fast_greedy
politik.fg <- igraph::cluster_fast_greedy(politik.ig)
# inspect clustering object
politik.fg
igraph::groups(politik.fg)
print(blockmodel(politik.n, politik.fg$membership)$block.model,
digits = 2)
df_comm <- data.frame(
Node = V(politik.ig)$name,
Community = politik.fg$membership,
Degree = degree_centrality
)
# 4. Find maximum degree for each community
highest_degree_nodes <- df_comm %>%
group_by(Community) %>%
filter(Degree == max(Degree)) %>%
ungroup()
highest_degree_nodes %>% arrange(-desc(Community))
# Create a logical vector for labeling nodes
label_nodes <- V(politik.ig)$name %in% highest_degree_nodes$Node
plot(politik.fg, politik.ig,
vertex.label = ifelse(label_nodes, V(politik.ig)$name, NA),  # Conditional labeling
vertex.label.cex = 1,
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
library(sentimentr)
#labeling based on the sentiment score
comments <- politik_final3$comment
get_sentiment_label <- function(ave_sentiment) {
if (ave_sentiment > 0.1) {
return("Positive")
} else if (ave_sentiment < -0.1) {
return("Negative")
} else {
return("Neutral")
}
}
sentiment_scores <- sentiment_by(x = comments, text.var = comments)
#adding the label for each author in the data set
politik_final3$sentiment <- sapply(sentiment_scores$ave_sentiment, get_sentiment_label)
# Create a graph object from the data frame
g <- graph_from_data_frame(politik.n, directed = FALSE)
# Add node attributes to the graph
V(g)$sentiment <- politik_final3$sentiment[match(V(g)$name, politik_final3$author)]
# Define color palette for categories
color_palette <- c("Negative" = "red", "Neutral" = "blue", "Positive" = "lightgreen")
# Visualize the network with colored nodes
plot(g, vertex.color = color_palette[V(g)$sentiment], layout = layout_nicely, vertex.label = NA, vertex.size = 7, isolates=TRUE, main = "Authors Network by Sentiment")
legend("bottomright", legend = c("Positive", "Neutral", "Negative"), col = c("lightgreen", "blue", "red"), pch = c(21, 21), title = "Node Sentiment")
#load packages
suppressPackageStartupMessages(library(network))
library(sna)
library(statnet)
politik.n <- network(adj_matrix, directed = FALSE)
politik.n
# Plot the network
plot(politik.n, displaylabels = F, label.cex=0.7, vertex.cex=1.5, displayisolates=F, main = "Authors Network")
suppressPackageStartupMessages(library(igraph))
# Create the igraph object
politik.ig <- graph_from_adjacency_matrix(adj_matrix, mode = "undirected")  # Undirected by default
# Calculate degree centrality for each node
degree_centrality <- degree(politik.ig, mode = "all")
# If nodes do not have names, you can use node IDs
if (is.null(V(politik.ig)$name)) {
V(politik.ig)$name <- as.character(1:vcount(politik.ig))
}
# Check node names
node_names <- V(politik.ig)$name
# Create a sample data frame with some values for each node
# Ensure the data frame has the same node identifiers as the graph
df <- data.frame(
author = node_names,  # Node names or IDs
value = runif(vcount(politik.ig), 1, 100)  # Random values between 1 and 100
)
# Convert degree centrality to a data frame
degree_centrality_df <- data.frame(
author = node_names,  # Node names or IDs
degree_centrality = degree_centrality  # Degree centrality values
)
# Merge the degree centrality data frame with the existing data frame
merged_df <- merge(df, degree_centrality_df, by = "author", all = TRUE)
merged_df2 <- merge(merged_df, politik_final2, by = "author", all = TRUE)
degree_scoredf <- select(merged_df2, c("degree_centrality", "score"))
# Calculate the correlation coefficient between 'score' and 'degree_centrality'
cor_matrix1 <- cor(degree_scoredf, use = "complete.obs")
cor_matrix1
# Create a logical vector for labeling nodes
# Create a custom labeling vector
node_labels <- rep(NA, vcount(network))
# Create a logical vector for labeling nodes
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:3]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
plot(politik.fg, politik.ig,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(politik.fg, network_no_isolated,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
plot(network_no_isolated,
vertex.color = membership(politik.fg),
main = "Network with Communities and without Isolated Nodes")
```
plot(network_no_isolated,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
plot(politik.fg, politik.ig,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
plot(politik.fg, network_no_isolated,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 1,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
plot(network_no_isolated,
vertex.label = node_labels,  # Conditional labeling
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities without isolated nodes and labeling top central nodes")
# Get the sizes of each community
community_sizes <- table(membership(politik.fg))
# Get the top 3 largest communities
top_communities <- names(sort(community_sizes, decreasing = TRUE))[1:3]
# Filter out vertices that are not in the top 3 communities
vertices_to_keep <- which(membership(politik.fg) %in% top_communities)
network_filtered <- delete_vertices(network_no_isolated, V(network_no_isolated)[!V(network_no_isolated) %in% vertices_to_keep])
plot(network_filtered,
vertex.color = membership(politik.fg)[V(network_filtered)],
main = "Network with Top 3 Communities and without Isolated Nodes")
plot(network_filtered,
vertex.color = membership(politik.fg)[V(network_filtered)],
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Network with Top 3 Communities and without Isolated Nodes")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities without isolated nodes and labeling top 5 central nodes")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities without isolated nodes and labeling top 5 central nodes")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities without isolated nodes and labeling top 5 central nodes")
# Identify nodes with high degree centrality (e.g., top 3)
top_nodes <- names(sort(degree_centrality, decreasing = TRUE))[1:5]
# Create a custom labeling vector
node_labels <- rep(NA, vcount(politik.ig))
# Set the labels for the nodes with high degree centrality
node_labels[top_nodes] <- top_nodes
# Identify isolated nodes
isolated_nodes <- which(degree(politik.ig) == 0)
# Remove isolated nodes from the network
network_no_isolated <- delete_vertices(politik.ig, isolated_nodes)
plot(network_no_isolated,
vertex.label = node_labels,
vertex.label.cex = 0.8,
vertex.color = membership(politik.fg),
vertex.label.color = "black",
vertex.shape = "sphere",
layout = layout_with_fr,
main = "Communities without isolated nodes and labeling top 5 central nodes")
